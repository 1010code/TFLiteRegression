{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorflowRegression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la96Ej93cPGj"
      },
      "source": [
        "## 建立資料集\n",
        "建立一個很簡單乘法器作為我們的迴歸範例。一個輸入對應一個輸出，其輸出為輸入的倍數。舉例來說，輸入 4 其輸出為 8。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhHl9rEi9Wfk"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.arange(1, 500, 1)\n",
        "y = np.arange(2, 1000, 2)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkNIeX93cY6o"
      },
      "source": [
        "## 搭建神經網路模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aoQ1Ias66zo"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2llSgWr9lGB"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_shape=[1]))\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=2), loss=keras.losses.mean_squared_error)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRH-nrmTfjTu",
        "outputId": "8c79b45b-fd94-468f-c214-93b8490a4711",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4QmeGnN9o38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efec06a8-6087-4be4-c1a2-5f08579989d5"
      },
      "source": [
        "model.fit(X, y, epochs=100)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 42916.7969\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9716.6758\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2083.0762\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 472.8735\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 94.4096\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 17.7075\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 5.1454\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.0494\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3086\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1093\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0546\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0371\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0268\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0189\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0133\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0101\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0065\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0045\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0032\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.6098e-04\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.0011e-04\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.2563e-04\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.8834e-04\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 1.2327e-04\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.2469e-05\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.9156e-05\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.3991e-05\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.4145e-05\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.6963e-06\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.8888e-06\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.1546e-06\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.7947e-07\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.8894e-07\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.4209e-07\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.0355e-07\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.1256e-08\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.3909e-08\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.3603e-08\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.6414e-08\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.0154e-08\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.7576e-08\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.5226e-09\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3135e-08\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.3133e-09\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.4325e-09\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.4973e-09\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2.7640e-09\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.2733e-09\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.3025e-09\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.0523e-09\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.6865e-09\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.7097e-13\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 6.2972e-13\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 5.8199e-13\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.1349e-13\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.0765e-13\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.0127e-13\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.9789e-14\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.4321e-14\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.7918e-14\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.6665e-14\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.6665e-14\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.2108e-14\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 7.1083e-14\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.6502e-14\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 1.2758e-14\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.2758e-14\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 1.2758e-14\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.2758e-14\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.1961e-14\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.1961e-14\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.1961e-14\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.1961e-14\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.0594e-14\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.2271e-15\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 9.2271e-15\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.2271e-15\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 9.2271e-15\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 8.6575e-15\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.6575e-15\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 8.6575e-15\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.6575e-15\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 8.6575e-15\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 8.6575e-15\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3670e-15\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3670e-15\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3670e-15\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3670e-15\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 1.3670e-15\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3670e-15\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3670e-15\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3670e-15\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3670e-15\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3670e-15\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3670e-15\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3670e-15\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3670e-15\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3670e-15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d51c0a390>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRMYJc2Qc3k4"
      },
      "source": [
        "## 測試模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRfdEDuW9woq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b663c1e3-ac4c-4bce-9cd0-86fc744b952c"
      },
      "source": [
        "model.predict([10])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[20.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtoobwRdc8CU"
      },
      "source": [
        "## 儲存模型\n",
        "打包成 `.h5` 可以將模型儲存起來下次，Python 要執行讀入模型即可立即預測。另外透過 TFLiteConverter 可以將 Python 訓練好的模型打包成 `.tflite` 格式，並提供手機設備進行預測。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8JbnfqA925I"
      },
      "source": [
        "model.save('regression.h5')"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fOEdZaPnFgP",
        "outputId": "09042463-c53d-461e-9cec-b0166271b3fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model('regression.h5')\n",
        "converter =tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "open(\"regression.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp_yifk_gg/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "832"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crV3NNCIdZcj"
      },
      "source": [
        "## TFLite Interpreter 測試模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-6UI9m3nHUS",
        "outputId": "05ec70d1-0b61-4f32-913f-8321f96f1a29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path='regression.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "input_data = np.array([[100]], dtype=np.float32)\n",
        "interpreter.set_tensor(input_index, input_data)\n",
        "interpreter.invoke()\n",
        "\n",
        "print(interpreter.get_tensor(output_index))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[200.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}